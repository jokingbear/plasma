{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opts\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import datasets as dts\n",
    "from plasma import gan_layers as layers, commons\n",
    "from plasma.training import trainer, gan_callbacks as callbacks, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), _ = dts.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train / 127.5 - 1\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(data.StandardDataset):\n",
    "    \n",
    "    def get_len(self):\n",
    "        return x_train.shape[0]\n",
    "    \n",
    "    def get_item(self, idx):\n",
    "        return x_train[idx, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ScaleCon(in_channels=1, out_channels=64, kernel_size=1, stride=1, padding=0, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): ScaleCon(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.2)\n",
       "  (4): Upsample(scale_factor=0.5, mode=bilinear)\n",
       "  (5): ScaleCon(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
       "  (6): LeakyReLU(negative_slope=0.2)\n",
       "  (7): Upsample(scale_factor=0.5, mode=bilinear)\n",
       "  (8): MiniBatchStd()\n",
       "  (9): ScaleCon(in_channels=257, out_channels=512, kernel_size=3, stride=1, padding=1, bias=True)\n",
       "  (10): LeakyReLU(negative_slope=0.2)\n",
       "  (11): ScaleCon(in_channels=512, out_channels=512, kernel_size=7, stride=1, padding=0, bias=True)\n",
       "  (12): Reshape(shape=(-1,))\n",
       "  (13): ScaleLinear(in_channels=512, out_channels=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = nn.Sequential(\n",
    "    layers.ScaleCon(1, 64, kernel_size=1, padding=0),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    layers.ScaleCon(64, 128),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Upsample(scale_factor=0.5, mode=\"bilinear\", align_corners=True),\n",
    "    layers.ScaleCon(128, 256),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Upsample(scale_factor=0.5, mode=\"bilinear\", align_corners=True),\n",
    "    layers.MiniBatchStd(),\n",
    "    layers.ScaleCon(257, 512),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    layers.ScaleCon(512, 512, kernel_size=7, padding=0),\n",
    "    commons.Reshape(-1),\n",
    "    layers.ScaleLinear(512, 1)\n",
    ").cuda(0)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (0): ScaleLinear(in_channels=128, out_channels=25088, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): Reshape(shape=(-1, 7, 7))\n",
       "  (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (4): ScaleCon(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
       "  (5): LeakyReLU(negative_slope=0.2)\n",
       "  (6): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (7): ScaleCon(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
       "  (8): LeakyReLU(negative_slope=0.2)\n",
       "  (9): ScaleCon(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
       "  (10): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Generator(nn.Sequential):\n",
    "    \n",
    "    def forward(self, x=None, batch_size=32):\n",
    "        x = x or torch.randn(batch_size, 128, device=\"cuda:0\")\n",
    "        \n",
    "        return super().forward(x)\n",
    "\n",
    "g = Generator(\n",
    "    layers.ScaleLinear(128, 7 * 7 * 512),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    commons.Reshape(-1, 7, 7),\n",
    "    nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True),\n",
    "    layers.ScaleCon(512, 256),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True),\n",
    "    layers.ScaleCon(256, 128),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    layers.ScaleCon(128, 1, kernel_size=1, padding=0),\n",
    "    nn.Tanh()\n",
    ").cuda(0)\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_opt = opts.Adam(d.parameters(), lr=1e-3, betas=(0, 0.99))\n",
    "g_opt = opts.Adam(g.parameters(), lr=1e-3, betas=(0, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainer.GANTrainer(d, g, d_opt, g_opt, nn.BCEWithLogitsLoss(), r1=10, x_device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "    callbacks.GenImage()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 / 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4befb1888c49aebe44dff29aeb0e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1875), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(train, epochs=100, callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
