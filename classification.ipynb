{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim as opts\n",
    "from plasma.training import Trainer, metrics, callbacks, data\n",
    "from plasma.modules import *\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), _ = mnist.load_data()\n",
    "\n",
    "x = x[y < 3] / 127.5 - 1\n",
    "y = y[y < 3]\n",
    "\n",
    "class Data(data.StandardDataset):\n",
    "    \n",
    "    def get_len(self):\n",
    "        return x.shape[0]\n",
    "    \n",
    "    def get_item(self, idx):\n",
    "        return x[idx, None], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): PrimaryGroupConv2d(in_channels=1, out_channels=16, kernel=3, stride=1, padding=1, bias=True)\n",
       "  (1): GroupBatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): GroupConv2d(in_channels=16, out_channels=32, kernel=3, stride=1, padding=1, dilation=1, groups=1, bias=True)\n",
       "  (4): GroupBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): GroupConv2d(in_channels=32, out_channels=32, kernel=3, stride=1, padding=1, dilation=1, groups=1, bias=True)\n",
       "  (8): GroupBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): GroupConv2d(in_channels=32, out_channels=64, kernel=3, stride=1, padding=1, dilation=1, groups=1, bias=True)\n",
       "  (11): GroupBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): GroupConv2d(in_channels=64, out_channels=64, kernel=3, stride=1, padding=1, dilation=1, groups=1, bias=True)\n",
       "  (15): GroupBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): ReLU(inplace=True)\n",
       "  (17): GroupConv2d(in_channels=64, out_channels=64, kernel=3, stride=1, padding=1, dilation=1, groups=1, bias=True)\n",
       "  (18): GroupBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace=True)\n",
       "  (20): Reshape(shape=(64, -1, 7, 7))\n",
       "  (21): GlobalAverage(axes=[2, 3, 4], keepdims=False)\n",
       "  (22): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(*[\n",
    "    PrimaryGroupConv2d(1, 16, kernel_size=3, padding=1),\n",
    "    GroupBatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    \n",
    "    GroupConv2d(16, 32, kernel_size=3, padding=1),\n",
    "    GroupBatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    \n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    \n",
    "    GroupConv2d(32, 32, kernel_size=3, padding=1),\n",
    "    GroupBatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    \n",
    "    GroupConv2d(32, 64, kernel_size=3, padding=1),\n",
    "    GroupBatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    \n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    \n",
    "    GroupConv2d(64, 64, kernel_size=3, padding=1),\n",
    "    GroupBatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    \n",
    "    GroupConv2d(64, 64, kernel_size=3, padding=1),\n",
    "    GroupBatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    \n",
    "    Reshape(64, -1, 7, 7),\n",
    "    GlobalAverage(rank=3),\n",
    "    nn.Linear(64, 3),\n",
    "    #nn.Softmax(dim=-1)\n",
    "])\n",
    "\n",
    "model.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = opts.RMSprop(model.parameters())\n",
    "opt = opts.SGD(model.parameters(), lr=0.25, momentum=0.9, nesterov=True)\n",
    "trainer = Trainer(model, opt, loss, metrics=[metrics.accuracy], x_device=\"cuda:0\", y_device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "    #callbacks.LrFinder(min_lr=1e-5, max_lr=2, epochs=3)\n",
    "    callbacks.WarmRestart(1e-5, 10, factor=2, periods=2, snapshot=False),\n",
    "    #callbacks.CLR(1e-5, 4),\n",
    "    #callbacks.TrainingScheduler(epochs=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5824042d0fb3472dae772731204263e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=290.0, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(Data(), callbacks=cbs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs[0].plot_data(target=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = Data()[2][0]\n",
    "ar = np.rot90(a, axes=[1, 2])\n",
    "ar = np.copy(ar)\n",
    "\n",
    "_, ax = plt.subplots(ncols=2)\n",
    "ax[0].imshow(a[0])\n",
    "ax[1].imshow(ar[0])\n",
    "plt.show()\n",
    "a.shape, a.max(), a.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.tensor(a[None], dtype=torch.float, device=\"cuda:0\")\n",
    "model.eval()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.tensor(ar[None], dtype=torch.float, device=\"cuda:0\")\n",
    "model.eval()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Rotate\n",
    "\n",
    "r = Rotate(limit=(-60, -60), border_mode=1, p=1)\n",
    "ar30 = r(image=a[0])[\"image\"]\n",
    "\n",
    "plt.imshow(ar30)\n",
    "ar30.max(), ar30.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.tensor(ar30[None, None], dtype=torch.float, device=\"cuda:0\")\n",
    "model.eval()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
